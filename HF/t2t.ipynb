{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fded4278",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355db0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2024.12.14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers torch sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f245a311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration,T5Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc2f0a5",
   "metadata": {},
   "source": [
    "![img](6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96addfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bb383bd5504135aa81eb3ff4bfefe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ADMIN\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "697f97382e274fc0af4b3a4220f6eff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29af788b29146ceb17e059da3160221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model_name=\"t5-small\" #you can use t5-base,t5-large,etc..\n",
    "\n",
    "tokenizer=T5Tokenizer.from_pretrained(model_name)\n",
    "model=T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e640b91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text=\"translate english to french: my name is kailas, and i love cricket\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "080f46a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids=tokenizer(input_text,\n",
    "                    return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2876dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated text:  Ich kenne kailas, et i love cricket\n"
     ]
    }
   ],
   "source": [
    "#generate translation\n",
    "outputs = model.generate(\n",
    "    input_ids,\n",
    "    max_length=50,\n",
    "    num_beams=4,\n",
    "    length_penalty=1.0,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "\n",
    "#decode the output tokens to text\n",
    "translated_text=tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"translated text: \", translated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747811da",
   "metadata": {},
   "source": [
    "**T5 model is not fully trained yet , so it can do some specific tasks only not accurately. sothat below code snippets use advanced model**\n",
    "\n",
    "**Use google colab for better performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "766e991b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ce220def62427baac181556944a9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ADMIN\\.cache\\huggingface\\hub\\models--facebook--nllb-200-3.3B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babea57e77104688a1b3109f9ec9eb4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)6cea38b9e3d5efcdcb9c251d6b40538e1aab555a:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960bb6b931e34791ba4fd524a0bcb972",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d55ad35ad694aebaafa9e2655be0171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d620d31a0e8041eb82839e98a14f556c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/808 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b48539ab2fc49bbbe5785fdf43c73dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216dd41851e748c4bda65ce4e74239f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d45763bdad4de0a227506cae3a13f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)18c1b46dc95be6e106c36df87d13175418b3972c:   0%|          | 0.00/6.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb564f60d3c4e87ac289877b784e9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532dae22972a470cbacf318d9f8d80a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)cf3e5af37956607f4c667d891ec069aa276be0be:   0%|          | 0.00/8.55G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156519f40d99457580a488286458d8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)4436d65cf94380c5ddd8f524cb878e090b27bb50:   0%|          | 0.00/2.10G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Use full model with lang_code_to_id support\n",
    "model_name = \"facebook/nllb-200-3.3B\"\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Set source and target languages\n",
    "src_lang = \"eng_Latn\"\n",
    "tgt_lang = \"tam_Taml\"\n",
    "\n",
    "# Set tokenizer source language\n",
    "tokenizer.src_lang = src_lang\n",
    "\n",
    "# Input text\n",
    "text = \"My name is Kailas and I love cricket.\"\n",
    "\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "# Generate translation\n",
    "translated_tokens = model.generate(\n",
    "    **inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang],  # ✅ This works with NLLB-3.3B\n",
    "    max_length=100\n",
    ")\n",
    "\n",
    "# Decode the translation\n",
    "translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "print(\"Translated to Tamil:\", translated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da910c",
   "metadata": {},
   "source": [
    "![img](7.png)\n",
    "\n",
    "[click here](https://huggingface.co/facebook/nllb-200-distilled-600M#languages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40b97f3",
   "metadata": {},
   "source": [
    "### Question and answering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd4af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering,AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cc08222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4fa3228f804b6da230736f033ecf0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ADMIN\\.cache\\huggingface\\hub\\models--bert-large-uncased-whole-word-masking-finetuned-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa95b478bad431ba9217a7d9e48cbd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e242df291044ac81fad049431d65cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ba910a60f44dfd954ac58b82bd0219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9efc396d41e4243a227c638062f2cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name=\"bert-large-uncased-whole-word-masking-finetuned-squad\" #you can use t5-base,t5-large,etc..\n",
    "\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "model=AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d55accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "The Indian Space Research Organisation (ISRO) is the space agency of the Government of India. It is responsible for India's space program and is known for missions like Chandrayaan and Mangalyaan. ISRO's headquarters is located in Bengaluru, Karnataka.\n",
    "\"\"\"\n",
    "\n",
    "question=\"Where is ISRO's headquarters located?\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b55a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize inputs\n",
    "inputs = tokenizer.encode_plus(question, context, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e02f568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model output\n",
    "import torch\n",
    "\n",
    "\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Extract answer start and end positions\n",
    "answer_start = torch.argmax(outputs.start_logits)\n",
    "answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "\n",
    "# Convert tokens to string\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea11096",
   "metadata": {},
   "outputs": [],
   "source": [
    "![img](8.png)\n",
    "\n",
    "![img](9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29cd7879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: bengaluru, karnataka\n"
     ]
    }
   ],
   "source": [
    "print(\"Answer:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
